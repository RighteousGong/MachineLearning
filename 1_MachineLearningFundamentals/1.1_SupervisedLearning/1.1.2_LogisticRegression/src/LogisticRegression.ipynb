{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:34:40.823824800Z",
     "start_time": "2024-01-16T09:34:40.787816200Z"
    }
   },
   "id": "9c458203a9e56090"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
    "y_train = np.array([0, 0, 0, 1, 1, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:34:41.385658100Z",
     "start_time": "2024-01-16T09:34:41.363662400Z"
    }
   },
   "id": "7a71f9f75222918c"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Sigmoid Function\n",
    "def sigmoid(z):\n",
    "    f_wb = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    return f_wb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:34:42.041128100Z",
     "start_time": "2024-01-16T09:34:42.016123Z"
    }
   },
   "id": "b8e2e19ba0243736"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Logistic loss function\n",
    "def function_cost(X, y, w, b):\n",
    "    m = X.shape[0]\n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        z_i = np.dot(X[i], w) + b\n",
    "        f_wb_i = sigmoid(z_i)\n",
    "        cost = cost + (-y[i] * np.log(f_wb_i) - (1 - y[i]) * np.log(f_wb_i))\n",
    "    \n",
    "    return cost"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:34:42.838044Z",
     "start_time": "2024-01-16T09:34:42.812278900Z"
    }
   },
   "id": "82cb035cef82d025"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 计算偏导数\n",
    "def function_gradient(X, y, w, b):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    dj_dw = np.zeros(n)\n",
    "    dj_db = 0.\n",
    "    \n",
    "    for i in range(m):\n",
    "        z_i = np.dot(X[i], w) + b\n",
    "        f_wb_i = sigmoid(z_i)\n",
    "        error = f_wb_i - y[i]\n",
    "        for j in range(n):\n",
    "            dj_dw[j] = dj_dw[j] + error * X[i, j]\n",
    "        dj_db = dj_db + error\n",
    "        \n",
    "    dj_dw = dj_dw / m\n",
    "    dj_db = dj_db / m\n",
    "    \n",
    "    return dj_dw, dj_db"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:35:46.969602800Z",
     "start_time": "2024-01-16T09:35:46.939596400Z"
    }
   },
   "id": "67cc544b6d414a05"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, w_star, b_star, alpha, iterations, cost_function, gradient_function):\n",
    "    m = X.shape[0]\n",
    "    if m == 0:\n",
    "        return 0\n",
    "    \n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_star)\n",
    "    b = b_star\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        cost = cost_function(X, y, w, b)\n",
    "        J_history.append(cost)\n",
    "        \n",
    "        dj_dw, dj_db = gradient_function(X, y, w, b)\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "    \n",
    "    return w, b, J_history"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:35:47.561780600Z",
     "start_time": "2024-01-16T09:35:47.539776Z"
    }
   },
   "id": "ce1dff56c76f2583"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "updated parameters: w:[5.28123029 5.07815608], b:-14.222409982019837\n"
     ]
    }
   ],
   "source": [
    "w_tmp  = np.zeros_like(X_train[0])\n",
    "b_tmp  = 0.\n",
    "alph = 0.1\n",
    "iters = 10000\n",
    "\n",
    "w_out, b_out, _ = gradient_descent(X_train, y_train, w_tmp, b_tmp, alph, iters, function_cost, function_gradient) \n",
    "print(f\"\\nupdated parameters: w:{w_out}, b:{b_out}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T09:35:48.862689600Z",
     "start_time": "2024-01-16T09:35:48.258720900Z"
    }
   },
   "id": "2215b546ee730841"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
